{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# theme = 'plotly_dark'\n",
    "theme = 'seaborn'\n",
    "#theme = 'plotly'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "\n",
    "path_to_model_def = '/home/kuba/projects/MedicationTakingData/resmodel' #this is were the .py file is \n",
    "path_to_dir_with_model_pt_file = '/home/kuba/projects/MedicationTakingData/resmodel/res_search_00/res_search_00_7'\n",
    "\n",
    "#the watch and recoding we willbe evaling\n",
    "WATCH_DIR = '/home/kuba/Documents/data/raw/listerine/3_final/03'\n",
    "recording = '2023-07-18_07_21_53'\n",
    "\n",
    "HERTZ = 100\n",
    "ACTIVITY_NAME_TO_CLASS_INDEX_MAPPING = {\n",
    "    'water':0,\n",
    "    'listerine':1,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_window(df, start, window_size):\n",
    "    \"\"\"\n",
    "    Prepare a window of accelerometer and gyroscope data for the model.\n",
    "    \"\"\"\n",
    "    window = df.iloc[start:start + window_size]\n",
    "    # Prepare accelerometer and gyroscope data\n",
    "    X_acc = torch.tensor([window[col].values for col in ['acc_x', 'acc_y', 'acc_z']], dtype=torch.float32)\n",
    "    X_gyro = torch.tensor([window[col].values for col in ['gyro_x', 'gyro_y', 'gyro_z']], dtype=torch.float32)\n",
    "    # Combine [1, 6, window_size]\n",
    "    return torch.cat((X_acc, X_gyro), dim=0).unsqueeze(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def smooth_predictions(prediction_sum, counts):\n",
    "    \"\"\"\n",
    "    Smooth predictions by averaging, handling divisions by zero.\n",
    "    \"\"\"\n",
    "    mask = counts > 0\n",
    "    averaged_predictions = np.zeros_like(prediction_sum)\n",
    "    averaged_predictions[mask] = prediction_sum[mask] / counts[mask]\n",
    "    return averaged_predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def viz_labels_and_predictions(sensor_data, y, model, window_size, stride, device, title):\n",
    "    \"\"\"\n",
    "    Visualize sensor data, true labels, and model predictions with smoothing.\n",
    "    \"\"\"\n",
    "    assert 'timestamp' in sensor_data.columns, \"Sensor data must include 'timestamp' column.\"\n",
    "    y_df = pd.DataFrame(y, columns=['labels'])\n",
    "    df = pd.concat([sensor_data, y_df], axis=1)\n",
    "    \n",
    "    prediction_sum = np.zeros(len(df))\n",
    "    counts = np.zeros(len(df))\n",
    "    \n",
    "    for i in range(0, len(df) - window_size + 1, stride):\n",
    "        X_combined = preprocess_window(df, i, window_size).to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            logits = torch.sigmoid(model(X_combined)).cpu().numpy()[0]\n",
    "            prediction_sum[i:i + window_size] += logits\n",
    "            counts[i:i + window_size] += 1\n",
    "    \n",
    "    averaged_predictions = smooth_predictions(prediction_sum, counts) * 15\n",
    "    \n",
    "    # Visualization\n",
    "    fig = go.Figure()\n",
    "    sensor_cols = ['acc_x', 'acc_y', 'acc_z', 'gyro_x', 'gyro_y', 'gyro_z']\n",
    "    for col in sensor_cols:\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=df['timestamp'], y=df[col],\n",
    "            name=f'{col.capitalize()}',\n",
    "            mode='lines', opacity=0.7\n",
    "        ))\n",
    "    \n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=df['timestamp'], y=df['labels'],\n",
    "        name='True Labels', mode='lines',\n",
    "        line=dict(color='black', width=2)\n",
    "    ))\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=df['timestamp'], y=averaged_predictions,\n",
    "        name='Predictions', mode='lines',\n",
    "        line=dict(color='red', width=3, dash='dash')\n",
    "    ))\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title=title, xaxis_title='Time (s)',\n",
    "        yaxis_title='Value', template='plotly',\n",
    "        legend=dict(yanchor=\"top\", y=0.99, xanchor=\"left\", x=0.01)\n",
    "    )\n",
    "    fig.show(renderer='browser')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_txt(dir):\n",
    "    txt_path = os.path.join(dir, f'desc.txt')\n",
    "    with open(txt_path, 'r') as f:\n",
    "        content = f.read()\n",
    "    dic = eval(content)\n",
    "    return dic['window_size'], dic['stride'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_data(recording_dir):\n",
    "    acc = pd.read_csv(f'{recording_dir}/acceleration.csv', skiprows=1)\n",
    "    acc['timestamp'] = (acc['timestamp'] - acc['timestamp'].iloc[0]) * 1e-9\n",
    "    \n",
    "    gyro = pd.read_csv(f'{recording_dir}/gyroscope.csv', skiprows=1)\n",
    "    gyro['timestamp'] = (gyro['timestamp'] - gyro['timestamp'].iloc[0]) * 1e-9\n",
    "    \n",
    "    # interpolate gyro data to match acc timestamps\n",
    "    gyro_interp = pd.DataFrame()\n",
    "    for axis in ['x', 'y', 'z']:\n",
    "        gyro_interp[axis] = np.interp(acc['timestamp'], gyro['timestamp'], gyro[axis])\n",
    "    \n",
    "    # combine acc and gyro data\n",
    "    sensor_data = pd.DataFrame()\n",
    "    sensor_data['timestamp'] = acc['timestamp']\n",
    "    sensor_data['acc_x'] = acc['x']\n",
    "    sensor_data['acc_y'] = acc['y']\n",
    "    sensor_data['acc_z'] = acc['z']\n",
    "    sensor_data['gyro_x'] = gyro_interp['x']\n",
    "    sensor_data['gyro_y'] = gyro_interp['y']\n",
    "    sensor_data['gyro_z'] = gyro_interp['z']\n",
    "    \n",
    "    return sensor_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#takes in label a to tensor for ML\n",
    "def json_to_tensor(labels_x, acc_len_x, acc_x):\n",
    "    y_new = torch.zeros(acc_len_x)-1\n",
    "\n",
    "    bouts = []\n",
    "    for hand in labels_x:\n",
    "        for action in labels_x[hand]:\n",
    "            for bout in labels_x[hand][action]:\n",
    "                y_new[(acc_x.timestamp > bout['start']) & (acc_x.timestamp < bout['end'])] = (ACTIVITY_NAME_TO_CLASS_INDEX_MAPPING[action] * 20 + 15)\n",
    "    return y_new\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/kuba/projects/MedicationTakingData/resmodel/res_search_00/res_search_00_7/res_search_00_7_bestF1.pth\n",
      "Using device: cuda:1\n",
      "Processing recording: 2023-07-18_07_21_53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_878028/1800783974.py:7: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:274.)\n",
      "  X_acc = torch.tensor([window[col].values for col in ['acc_x', 'acc_y', 'acc_z']], dtype=torch.float32)\n"
     ]
    }
   ],
   "source": [
    "sys.path.append(path_to_model_def)\n",
    "head_tail = os.path.split(path_to_dir_with_model_pt_file)\n",
    "model_path = os.path.join(path_to_dir_with_model_pt_file, f'{head_tail[1]}_bestF1.pth')\n",
    "\n",
    "window_size, stride = read_txt(path_to_dir_with_model_pt_file)\n",
    "print(model_path)\n",
    "\n",
    "# Load model\n",
    "model = torch.load(model_path)\n",
    "model.eval()\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "model = model.to(device)\n",
    "\n",
    "# get recordings list\n",
    "if recording == '*':\n",
    "    recordings = sorted(os.listdir(WATCH_DIR))\n",
    "else:\n",
    "    recordings = [recording]\n",
    "\n",
    "for rec in recordings:\n",
    "    if rec == '.DS_Store':\n",
    "        continue\n",
    "        \n",
    "    print(f\"Processing recording: {rec}\")\n",
    "    recording_dir = f'{WATCH_DIR}/{rec}'\n",
    "    \n",
    "    sensor_data = load_and_preprocess_data(recording_dir)\n",
    "    \n",
    "    # get labels\n",
    "    with open(f'{recording_dir}/labels.json', 'r') as f:\n",
    "        labels = json.load(f)\n",
    "    \n",
    "    # convert labels to tensor\n",
    "    data_len = len(sensor_data)\n",
    "    y = json_to_tensor(labels, data_len, sensor_data)\n",
    "    \n",
    "    # viz with predictions\n",
    "    viz_labels_and_predictions(\n",
    "        sensor_data,\n",
    "        y,\n",
    "        model,\n",
    "        window_size=window_size,\n",
    "        stride=stride,\n",
    "        device=device,\n",
    "        title=recording_dir\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
